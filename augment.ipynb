{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator , load_img, img_to_array, array_to_img\nfrom keras.datasets import mnist\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, auc, roc_curve\nfrom tensorflow.keras.applications import InceptionResNetV2  # Use Inception-ResNetV2\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-18T21:07:34.126399Z","iopub.execute_input":"2023-09-18T21:07:34.126781Z","iopub.status.idle":"2023-09-18T21:07:34.135703Z","shell.execute_reply.started":"2023-09-18T21:07:34.126748Z","shell.execute_reply":"2023-09-18T21:07:34.134552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Check GPU availability\nprint(tf.test.is_gpu_available())\nprint(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:07:34.138071Z","iopub.execute_input":"2023-09-18T21:07:34.138687Z","iopub.status.idle":"2023-09-18T21:07:34.151506Z","shell.execute_reply.started":"2023-09-18T21:07:34.138653Z","shell.execute_reply":"2023-09-18T21:07:34.150406Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"True\n[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset and visualize images\nlabels = os.listdir(\"/kaggle/input/drowsiness-dataset/train\")\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:07:34.153818Z","iopub.execute_input":"2023-09-18T21:07:34.154171Z","iopub.status.idle":"2023-09-18T21:07:34.164576Z","shell.execute_reply.started":"2023-09-18T21:07:34.154140Z","shell.execute_reply":"2023-09-18T21:07:34.163581Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#import os\ndirectory_path = \"/kaggle/working/augmented_dataset/\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/Closed\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/Open\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/no_yawn\"\nos.makedirs(directory_path)\ndirectory_path = \"/kaggle/working/augmented_dataset/train/yawn\"\nos.makedirs(directory_path)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:07:34.168151Z","iopub.execute_input":"2023-09-18T21:07:34.168476Z","iopub.status.idle":"2023-09-18T21:07:34.176815Z","shell.execute_reply.started":"2023-09-18T21:07:34.168453Z","shell.execute_reply":"2023-09-18T21:07:34.175891Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Closed \n# Define your dataset directory and other parameters\ndataset_dir = '/kaggle/input/drowsiness-dataset'\noutput_dir = '/kaggle/working/augmented_dataset'\naugmentation_factor = 5  # Adjust this to determine how much you want to augment your dataset\n\n# Create an ImageDataGenerator with augmentation settings\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\n# Load and augment images from the dataset\nfor root, _, files in os.walk(dataset_dir):\n    for filename in files:\n        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):  # Adjust extensions as needed\n            img = load_img(os.path.join(root, filename))\n            x = img_to_array(img)\n            x = np.expand_dims(x, axis=0)\n            \n            i = 0\n            for batch in datagen.flow(x, batch_size=1):\n                augmented_image = array_to_img(batch[0])\n                augmented_image.save(os.path.join(output_dir, f'augmented_{i}_{filename}'))\n                i += 1\n                if i >= augmentation_factor:\n                    break\n\nprint(f'Dataset augmentation complete. Augmented {augmentation_factor} times.')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:07:34.178714Z","iopub.execute_input":"2023-09-18T21:07:34.178999Z","iopub.status.idle":"2023-09-18T21:19:23.170345Z","shell.execute_reply.started":"2023-09-18T21:07:34.178976Z","shell.execute_reply":"2023-09-18T21:19:23.169167Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Dataset augmentation complete. Augmented 5 times.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset and visualize images\nlabels = os.listdir(\"/kaggle/working/augmented_dataset\")\n\n# Load the data using ImageDataGenerator\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    rotation_range=30\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:26:52.011764Z","iopub.execute_input":"2023-09-18T21:26:52.012648Z","iopub.status.idle":"2023-09-18T21:26:52.026823Z","shell.execute_reply.started":"2023-09-18T21:26:52.012616Z","shell.execute_reply":"2023-09-18T21:26:52.025791Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Load the dataset and split into training and testing sets\ndirectory = \"../kaggle/working/augmented_dataset\"\ntarget_size = (240, 240)\nbatch_size = 4000  # Adjust batch size as needed\n\n# Load the dataset and split into training and testing sets\ndata = datagen.flow_from_directory(\n    directory,\n    target_size=target_size,\n    batch_size=batch_size,  # Specify batch size here\n    class_mode='categorical',\n    subset='training'\n)\n\n# Split the data into training and testing sets\nx, y = data.next()\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.187242Z","iopub.execute_input":"2023-09-18T21:19:23.187887Z","iopub.status.idle":"2023-09-18T21:19:23.446052Z","shell.execute_reply.started":"2023-09-18T21:19:23.187835Z","shell.execute_reply":"2023-09-18T21:19:23.442927Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m  \u001b[38;5;66;03m# Adjust batch size as needed\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the dataset and split into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify batch size here\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[1;32m     16\u001b[0m x, y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnext()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../kaggle/working/augmented_dataset'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../kaggle/working/augmented_dataset'","output_type":"error"}]},{"cell_type":"code","source":"# Encode the labels using one-hot encoding\nlabel_bin = LabelBinarizer()\ny_train = label_bin.fit_transform(y_train)\ny_test = label_bin.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.447430Z","iopub.status.idle":"2023-09-18T21:19:23.447953Z","shell.execute_reply.started":"2023-09-18T21:19:23.447675Z","shell.execute_reply":"2023-09-18T21:19:23.447708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the Inception-ResNetV2 base model\nbase_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.449674Z","iopub.status.idle":"2023-09-18T21:19:23.450176Z","shell.execute_reply.started":"2023-09-18T21:19:23.449935Z","shell.execute_reply":"2023-09-18T21:19:23.449959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add custom layers for classification on top of the base model\nmodel = Sequential([\n    base_model,\n    GlobalAveragePooling2D(),\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(4, activation='sigmoid')\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.451827Z","iopub.status.idle":"2023-09-18T21:19:23.452323Z","shell.execute_reply.started":"2023-09-18T21:19:23.452071Z","shell.execute_reply":"2023-09-18T21:19:23.452092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Freeze the layers in the base model\nfor layer in base_model.layers:\n    layer.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.453950Z","iopub.status.idle":"2023-09-18T21:19:23.454424Z","shell.execute_reply.started":"2023-09-18T21:19:23.454176Z","shell.execute_reply":"2023-09-18T21:19:23.454199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile the model\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.456063Z","iopub.status.idle":"2023-09-18T21:19:23.456588Z","shell.execute_reply.started":"2023-09-18T21:19:23.456295Z","shell.execute_reply":"2023-09-18T21:19:23.456342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model\nhist = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), batch_size=45)  # Specify batch size here","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.458270Z","iopub.status.idle":"2023-09-18T21:19:23.458743Z","shell.execute_reply.started":"2023-09-18T21:19:23.458496Z","shell.execute_reply":"2023-09-18T21:19:23.458518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model\nmodel.save(\"drowsiness_inceptionv4.h5\")\nmodel.save(\"drowsiness_inceptionv4.model\")","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.460318Z","iopub.status.idle":"2023-09-18T21:19:23.460781Z","shell.execute_reply.started":"2023-09-18T21:19:23.460538Z","shell.execute_reply":"2023-09-18T21:19:23.460560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot accuracy and loss\naccuracy = hist.history['accuracy']\nval_accuracy = hist.history['val_accuracy']\nloss = hist.history['loss']\nval_loss = hist.history['val_loss']\nepochs = range(len(accuracy))\n\nplt.plot(epochs, accuracy, \"b\", label=\"training accuracy\")\nplt.plot(epochs, val_accuracy, \"r\", label=\"validation accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training & Validation Accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.462394Z","iopub.status.idle":"2023-09-18T21:19:23.462883Z","shell.execute_reply.started":"2023-09-18T21:19:23.462618Z","shell.execute_reply":"2023-09-18T21:19:23.462641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs, loss, \"b\", label=\"training loss\")\nplt.plot(epochs, val_loss, \"r\", label=\"validation loss\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Training & Validation Loss')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.464435Z","iopub.status.idle":"2023-09-18T21:19:23.464924Z","shell.execute_reply.started":"2023-09-18T21:19:23.464658Z","shell.execute_reply":"2023-09-18T21:19:23.464681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions and evaluate the model\ny_true = np.argmax(y_test, axis=1)\ny_pred = model.predict(x_test)\ny_pred_classes = np.argmax(y_pred, axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.466534Z","iopub.status.idle":"2023-09-18T21:19:23.467048Z","shell.execute_reply.started":"2023-09-18T21:19:23.466779Z","shell.execute_reply":"2023-09-18T21:19:23.466804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion Matrix\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes)\n\n# Plot Confusion Matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.468724Z","iopub.status.idle":"2023-09-18T21:19:23.469512Z","shell.execute_reply.started":"2023-09-18T21:19:23.469182Z","shell.execute_reply":"2023-09-18T21:19:23.469205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_mtx)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.471039Z","iopub.status.idle":"2023-09-18T21:19:23.471496Z","shell.execute_reply.started":"2023-09-18T21:19:23.471265Z","shell.execute_reply":"2023-09-18T21:19:23.471287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy Score\naccuracy = np.sum(y_true == y_pred_classes) / len(y_true)\nprint(\"Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.473111Z","iopub.status.idle":"2023-09-18T21:19:23.473569Z","shell.execute_reply.started":"2023-09-18T21:19:23.473334Z","shell.execute_reply":"2023-09-18T21:19:23.473356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute ROC curves and AUC for each class\nn_classes = 4\nfpr = dict()\ntpr = dict()\n\nroc_auc = dict()\n\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Plot the ROC curves for each class\nplt.figure(figsize=(8, 6))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], lw=2, label='Class {} (AUC = {:.2f})'.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-18T21:19:23.477707Z","iopub.status.idle":"2023-09-18T21:19:23.478976Z","shell.execute_reply.started":"2023-09-18T21:19:23.478686Z","shell.execute_reply":"2023-09-18T21:19:23.478723Z"},"trusted":true},"execution_count":null,"outputs":[]}]}